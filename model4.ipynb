{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASvEhNt451GV"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import BertTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYqJOF0ZVhZ4",
        "outputId": "480cc042-7001-4d05-ab7a-d3cb3607b14d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set environment variable for debugging CUDA errors\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "# Check device availability and set up properly\n",
        "def setup_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "        # Clear cache to prevent memory issues\n",
        "        torch.cuda.empty_cache()\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"Using CPU\")\n",
        "    return device\n",
        "\n",
        "device = setup_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "_pONQA9G6jK0",
        "outputId": "b95b1c83-0279-45a1-9bee-cdd8148df683"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510,
          "referenced_widgets": [
            "97e49df821774e03bb5872222012646e",
            "4741faaae7614385b4712ba45c3bca22",
            "d81a1d7fc5494d67820812d937bdbf9e",
            "4574f2568ad74d3eab51d79b0805b17b",
            "cddc4b5c0eb14666ab0fc4728b7e26ca",
            "04f13eddeedf44bdb9d1ef9526b6509f",
            "cccfeab0c8034a948e1a7f179725682c",
            "7021e03c1e5b48bbbb2bae284f023f63",
            "5a0d87942f5f4e089e5c5c34fcf1e13f",
            "cbdfdfdbdd90408da82c3d8e40116624",
            "b33121102f724fb7899eaaee00eb4196",
            "6ad7c4a253fa4d55811e40dbf1e87195",
            "8895c2b7787c40b88a1d358c5ed88819",
            "3cbfc5e2b4e44e558f753576c74de94f",
            "1ce436ab6db94bb89a079850f00aff14",
            "8bd38003c8974b7282dcebd7bebefb66",
            "df4c952337744589b1e8438de4cf7d83",
            "a98c7de0723c4cfb894577992ab94252",
            "f7dd8351417e4ea6810a7049c8c0a077",
            "d0d92058f7134cbe81d92d9d1aefac79",
            "59aa457b579149e9aac573383e143e2e",
            "cfed855e6d92485fbff2d230ae981070",
            "45c41bf5fdc242d3add99d1e33206024",
            "d203f71b812b4c3aa40510c2585f2858",
            "3b360e40705249b4a65740066d8fc63a",
            "b788342967264f208709ae41eb307fd5",
            "f336619ec3e740f5b9abab06de4543ea",
            "89614871545f4cc8ba15dc68e9b4df60",
            "47efc3c7ebaf4d81be073c5689ae01cf",
            "d64682001f044a47b03e52deb4dfc0b6",
            "8eed8ac16f4b4594815025d2ec8ec9a6",
            "d07591c5250c4fe7bfbea0ac5d1470a6",
            "44c3a9e057544f69bc45228d17c141ca",
            "b2e0e6f2af064f919c9ac0d2e67c676e",
            "7737ae92c1d74b2b993b0418352d8ca5",
            "bdb437238097438b844c0712888c6f66",
            "7dd991670fcc43249755369ab45f7e27",
            "dfd24c3fc34c42998440c7a19ad76ffa",
            "1b5cb1da96144a7a85754401fde68df2",
            "bf204acc5b9d4698b9d7b957f064289b",
            "2e1001f80a6346d59ccead5788961d14",
            "3aac4ffca40f45b195940646f02c1c40",
            "afe4828b00684746bd7797c6632b5017",
            "76b0f40e4403418285f9f5ee45d808de"
          ]
        },
        "id": "AKbBaTT56OqM",
        "outputId": "caa5c4b2-0785-48b5-d549-459a20567c1d"
      },
      "outputs": [],
      "source": [
        "CSV_FILE_PATH = \"Training_clean.csv\"  # Change this to your CSV file path\n",
        "MODEL_NAME = 'bert-base-uncased'  # Use 'distilbert-base-uncased' for faster training\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 8  # Reduce to 8 or 4 if you get memory errors\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Load data\n",
        "# print(\"Loading dataset...\")\n",
        "df = pd.read_csv(CSV_FILE_PATH)\n",
        "# print(\"Dataset loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "# print(\"\\ndfset columns:\")\n",
        "print(df.columns.tolist())\n",
        "# print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xdLfcS5xDVN"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df[\"type\"])\n",
        "\n",
        "train_text, val_text, train_label, val_label =train_test_split(\n",
        "    df['tweet'].tolist(),\n",
        "    df['label'].tolist(),\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=df['label']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWgRy2DiwpCm"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60CwkCdExtzN"
      },
      "outputs": [],
      "source": [
        "train_dataset = TweetDataset(train_text, train_label, tokenizer)\n",
        "val_dataset = TweetDataset(val_text, val_label, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E30ox9C6xyeM",
        "outputId": "1ddad0c4-6921-4f7a-f381-c68dd2463f44"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(le.classes_)\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMhu72i8x_YZ"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vcRi6ctyBC6",
        "outputId": "360463e5-7e33-4271-ae20-c2d899a595d1"
      },
      "outputs": [],
      "source": [
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    total_loss = 0\n",
        "    for batch in loop:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_description(f'Epoch {epoch+1}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f'Average Training Loss: {avg_train_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo99orr_yUVB",
        "outputId": "4d540767-63c3-4d5e-df16-c3173800d529"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "val_preds = []\n",
        "val_true = []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        val_preds.extend(preds.cpu().numpy())\n",
        "        val_true.extend(labels.cpu().numpy())\n",
        "\n",
        "print(f'Validation Classification Report Epoch {epoch+1}:')\n",
        "print(classification_report(val_true, val_preds, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbHK9UjtjETY",
        "outputId": "c668ff6b-c1e8-474a-b52f-9308f4445224"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "SAVE_DIRECTORY = './save_gbv_bert_model'\n",
        "\n",
        "model.save_pretrained(SAVE_DIRECTORY)\n",
        "tokenizer.save_pretrained(SAVE_DIRECTORY)\n",
        "print(f\"Model saved to {SAVE_DIRECTORY}\")\n",
        "\n",
        "# Optional: Load model (for future use)\n",
        "def load_saved_model(model_directory):\n",
        "    \"\"\"Load a previously saved model\"\"\"\n",
        "    try:\n",
        "        loaded_model = BertForSequenceClassification.from_pretrained(model_directory)\n",
        "        loaded_tokenizer = BertTokenizer.from_pretrained(model_directory)\n",
        "        loaded_model.to(device)\n",
        "        print(f\"Model loaded from {model_directory}\")\n",
        "        return loaded_model, loaded_tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example of loading (uncomment to test)\n",
        "# loaded_model, loaded_tokenizer = load_saved_model(SAVE_DIRECTORY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9T0K-HmjPsK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "2e948d03",
        "outputId": "9550e4db-fbf9-4ce3-dd01-7d57c1227517"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming the uploaded file is named \"Test.csv\"\n",
        "for filename in uploaded.keys():\n",
        "    print(f'User uploaded file \"{filename}\" with length {len(uploaded[filename])} bytes')\n",
        "    NEW_CSV_FILE_PATH = filename # Use the actual uploaded filename\n",
        "\n",
        "new_data = pd.read_csv(NEW_CSV_FILE_PATH)\n",
        "\n",
        "print(\"\\nNew dataset loaded successfully!\")\n",
        "print(f\"Dataset shape: {new_data.shape}\")\n",
        "print(\"\\nFirst few rows of the new dataset:\")\n",
        "print(new_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7c61e4d",
        "outputId": "e8b64afb-cc20-4f16-9e47-88c4cfc1cbd9"
      },
      "outputs": [],
      "source": [
        "# Create a placeholder for labels for the new data\n",
        "placeholder_labels = [0] * len(new_data)\n",
        "\n",
        "# Create a dataset for the new data\n",
        "new_dataset = TweetDataset(new_data['tweet'], placeholder_labels, tokenizer, MAX_LENGTH)\n",
        "\n",
        "# Create a data loader for the new data\n",
        "new_loader = DataLoader(new_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Data loader for new data created successfully!\")\n",
        "print(f\"Number of batches in the new data loader: {len(new_loader)}\")\n",
        "\n",
        "# Test the new data loader\n",
        "sample_batch_new = next(iter(new_loader))\n",
        "print(f\"\\nSample batch shapes from new data loader:\")\n",
        "print(f\"Input IDs: {sample_batch_new['input_ids'].shape}\")\n",
        "print(f\"Attention Mask: {sample_batch_new['attention_mask'].shape}\")\n",
        "print(f\"Labels: {sample_batch_new['labels'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445b62e6",
        "outputId": "a268f4a0-6485-40d0-8793-7e37efddf926"
      },
      "outputs": [],
      "source": [
        "# 1. Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# 2. Initialize an empty list called new_predictions to store the model's predictions.\n",
        "new_predictions = []\n",
        "\n",
        "print(\"Predicting on new data...\")\n",
        "\n",
        "# 3. Iterate through the new_loader using a for loop and tqdm for a progress bar.\n",
        "for batch in tqdm(new_loader, desc=\"Predicting\"):\n",
        "    # 4. For each batch, move the input_ids and attention_mask to the appropriate device (device).\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "    # 5. Disable gradient calculation using torch.no_grad().\n",
        "    with torch.no_grad():\n",
        "        # 6. Pass the input_ids and attention_mask to the model to get the outputs.\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # 7. Get the predicted class by finding the index of the maximum value in the outputs.logits along the last dimension.\n",
        "    batch_predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # 8. Extend the new_predictions list with the predicted classes, converting them to NumPy arrays and moving them to the CPU.\n",
        "    new_predictions.extend(batch_predictions.cpu().numpy())\n",
        "\n",
        "print(\"\\nPrediction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f34c8a8",
        "outputId": "35f3abe0-52ef-412f-cad8-4d21f8049afc"
      },
      "outputs": [],
      "source": [
        "# Create the label_map dictionary from the LabelEncoder classes\n",
        "label_map = {i: label for i, label in enumerate(le.classes_)}\n",
        "\n",
        "# 1. Invert the label_map dictionary to create a mapping from numerical IDs back to the original string labels.\n",
        "id_to_label = {i: label for i, label in enumerate(le.classes_)}\n",
        "\n",
        "# 2. Create an empty list called predicted_labels.\n",
        "predicted_labels = []\n",
        "\n",
        "# 3. Iterate through the new_predictions list (which contains the numerical predictions).\n",
        "# 4. For each numerical prediction in new_predictions, use the id_to_label dictionary to find the corresponding string label.\n",
        "# 5. Append the retrieved string label to the predicted_labels list.\n",
        "for prediction in new_predictions:\n",
        "    predicted_labels.append(id_to_label[prediction])\n",
        "\n",
        "# 6. Print a message confirming that the numerical predictions have been mapped back to the original labels.\n",
        "print(\"Numerical predictions have been mapped back to the original labels.\")\n",
        "print(f\"Example predicted labels: {predicted_labels[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0979ecfd",
        "outputId": "27391a1a-2a27-4ce6-894a-3f26b39b5520"
      },
      "outputs": [],
      "source": [
        "# 1. Create a new pandas DataFrame named results_df.\n",
        "results_df = pd.DataFrame()\n",
        "\n",
        "# 2. Add a column named 'Tweet_ID' to results_df and populate it with the 'Tweet_ID' column from the original new_data DataFrame.\n",
        "results_df['Tweet_ID'] = new_data['Tweet_ID']\n",
        "\n",
        "# 3. Add a column named 'Predicted_Type' to results_df and populate it with the predicted_labels list.\n",
        "results_df['Predicted_Type'] = predicted_labels\n",
        "\n",
        "# 4. Save results_df to a CSV file named 'predictions.csv'.\n",
        "output_filename = 'predictions.csv'\n",
        "results_df.to_csv(output_filename, index=False)\n",
        "\n",
        "# 5. Print a confirmation message.\n",
        "print(f\"Prediction results saved to {output_filename}\")\n",
        "print(\"\\nFirst few rows of the results DataFrame:\")\n",
        "print(results_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "e5970802",
        "outputId": "98d8cff3-b42c-4537-c9c2-7edd971cf29e"
      },
      "outputs": [],
      "source": [
        "#download the file to your local storage downloads folder\n",
        "files.download('predictions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": { "state": {}}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
